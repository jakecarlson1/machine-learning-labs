{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7 - Convolutional Neural Networks\n",
    "\n",
    "### Eric Smith and Jake Carlson\n",
    "\n",
    "## Introduction\n",
    "In this lab, we will develop a multi-layer perceptron to perform classification on the CIFAR-10 data set. Similar to Lab 3, we will subset the data set to images of trucks and automobiles. The original data set has 60,000 images. 50,000 of these are training images and 10,000 are test images. The images are 32x32 pixels and contain objects from 10 classes. The classes are listed below.\n",
    "- airplane\n",
    "- automobile\n",
    "- bird\n",
    "- cat\n",
    "- deer\n",
    "- dog\n",
    "- frog\n",
    "- horse\n",
    "- ship\n",
    "- truck\n",
    "\n",
    "This data set was collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton for their paper <i>Learning Multiple Layers of Features from Tiny Images</i>. In this study, the authors use several filters to train their model to learn interesting regularities in the set of images, rather than focus on correlations between nearby pixels [1].\n",
    "\n",
    "For this lab, we will use the images of automobile, trucks, and birds. The trucks, in this case, are semi-trucks. We have been guaranteed by the people who generated the data set that these three classes are mutually exclusive. The automobile class will have images of sedans and SUVs. The truck class will have big trucks only. Neither class has images of pickup trucks.\n",
    "\n",
    "## Business Understanding\n",
    "\n",
    "### Motivations\n",
    "The law treats cars and trucks differently on the road. Trucks often have to stop at weigh stations so their contents can be verified. It would be useful to have a tool that can distinguish between cars and trucks. Once a truck has been identified, a record of the truck and its location can be made so that Customs or local authorities can make sure the truck is checked at the next weigh station.\n",
    "\n",
    "The classification system developed could be deployed in conjunction with CCTV cameras on the highway. This would give authorities real time metrics on how many trucks are passing through an area. If a truck passes by two cameras, our model could incorporate the location of each camera and the time between sightings. This would reduce the necessity of having police officers on the road to monitor the speed of semi-trucks.\n",
    "\n",
    "If a truck is identified as speeding, a police officer could be dispatched to monitor the vehicle. Using a distributed network of cameras on the highway would mean officers could spend more time patrolling residential and commerical areas. The average annual income for a Texas state trooper is \\$60,612 [2]. Positioning a trooper on the highway costs roughly \\$31 an hour. Meanwhile, the cost of running a CCTV camera 24/7 is approximately 54 cents per month [3].\n",
    "\n",
    "If a trooper is positioned on the highway, people alter their behaviors because they recognize that they are being monitored. If a criminal organization is transporting illicit substances, they can have a lead car drive ahead of the transport truck so officers can be located before the truck passes through an area. However, people often don't recognize when they are being monitored by CCTV camera.\n",
    "\n",
    "### Objectives\n",
    "Our main objective is to accurately pick out a semi-truck from a sea of automobiles. A state trooper can accurately distinguish between a semi-truck and an automobile 100% of the time. But troopers rotate in and out of an area, leaving gaps in the amount of time a road is being monitored. Take the following simplified case: one trooper is assigned to watch a highway for one business day where they start at 8am, end at 5pm, and take an hour for lunch. A second trooper rotates in to monitor the highway starting at 6pm and ending at 3am. The percentage of time the road is covered is given by\n",
    "<br><br>\n",
    "$$t_{officer} = \\frac{24 - ((6-5) + 1 + (6-3))}{24}\\times100 = 79.2\\%$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "So 79% is our threshold to beat. In order for our algorithm to be useful to authorities, it must minimize the number of trucks that slip through undetected. We will do this by measuring the performance of our model with Recall such that\n",
    "<br><br>\n",
    "\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "<br>\n",
    "Where TP is the true positive rate, and FN is the false negative rate.\n",
    "\n",
    "Therefore, our objective is to minimize the number of false negatives produced and reach 79% recall to be a viable replacement for police officers.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "### Data Cleaning\n",
    "We will start by loading the images and subsetting to 1000 images. We will use a ratio of cars to trucks that most closely matches real-world driving conditions. A project at The George Washington University [2] puts the percentage of highway vehicles that are trucks anywhere between 5% and 25% depeding on the stretch of road. We will use 25% because it balances the classes somewhat while still conforming to a real-world estimate of the ratio between trucks and cars. We will reduce the dimensionality of our images by transforming them to gray scale. This will reduce the number of features for each image from 3,072 to 1,024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21093</th>\n",
       "      <td>21094</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47437</th>\n",
       "      <td>47438</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47504</th>\n",
       "      <td>47505</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6784</th>\n",
       "      <td>6785</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>2216</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "21093  21094  truck\n",
       "47437  47438  truck\n",
       "47504  47505  truck\n",
       "6784    6785  truck\n",
       "2215    2216  truck"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_labels = pd.read_csv('../Lab3/data/labels.csv')\n",
    "df_labels = df_labels[ df_labels.label.isin(['automobile', 'truck']) ]\n",
    "df_labels = pd.concat([df_labels[df_labels.label == \"truck\"].sample(n=250),\n",
    "                      df_labels[df_labels.label == \"automobile\"].sample(n=750)])\n",
    "\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 1025 entries, label to 1023\n",
      "dtypes: object(1025)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# reads a png and returns a list of all pixel values in order r, g, b\n",
    "def get_img_as_rgb_row(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    if len(img.split()) == 4:\n",
    "        # remove alpha if present\n",
    "        r, g, b, a = img.split()\n",
    "        img = Image.merge(\"RGB\", (r, g, b))\n",
    "    r, g, b = img.split()\n",
    "    r = list(r.getdata())\n",
    "    g = list(g.getdata())\n",
    "    b = list(b.getdata())\n",
    "    # convert to gray scale\n",
    "    img_list = [(r[i] * 0.2989 + g[i] * 0.5870 + b[i] * 0.1140) for i in range(len(r))]\n",
    "    return img_list\n",
    "\n",
    "# generate column names\n",
    "cols = ['label']\n",
    "for i in range(1024):\n",
    "    cols.append(\"{}\".format(i))\n",
    "\n",
    "# create df and extract color values for all car and truck images\n",
    "df = pd.DataFrame(columns=cols, index=range(len(df_labels.id.tolist())))\n",
    "data_dir = \"../Lab3/data/cifar-10/\"\n",
    "idx = 0\n",
    "for r in df_labels.iterrows():\n",
    "    entry = [r[1].label]\n",
    "    entry.extend(get_img_as_rgb_row(\"{}{}.png\".format(data_dir, r[1].id)))\n",
    "    df.loc[idx] = entry\n",
    "    idx += 1\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>label_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>truck</td>\n",
       "      <td>158.756</td>\n",
       "      <td>200.98</td>\n",
       "      <td>248.317</td>\n",
       "      <td>245.317</td>\n",
       "      <td>247.203</td>\n",
       "      <td>248.203</td>\n",
       "      <td>250.203</td>\n",
       "      <td>249.975</td>\n",
       "      <td>247.975</td>\n",
       "      <td>...</td>\n",
       "      <td>236.824</td>\n",
       "      <td>235.824</td>\n",
       "      <td>235.824</td>\n",
       "      <td>235.824</td>\n",
       "      <td>234.824</td>\n",
       "      <td>233.938</td>\n",
       "      <td>233.938</td>\n",
       "      <td>232.938</td>\n",
       "      <td>233.938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>truck</td>\n",
       "      <td>147.931</td>\n",
       "      <td>130.922</td>\n",
       "      <td>123.11</td>\n",
       "      <td>152.324</td>\n",
       "      <td>161.039</td>\n",
       "      <td>191.824</td>\n",
       "      <td>242.378</td>\n",
       "      <td>252.975</td>\n",
       "      <td>253.747</td>\n",
       "      <td>...</td>\n",
       "      <td>49.3927</td>\n",
       "      <td>47.795</td>\n",
       "      <td>35.0459</td>\n",
       "      <td>42.5397</td>\n",
       "      <td>87.0962</td>\n",
       "      <td>59.3179</td>\n",
       "      <td>72.4244</td>\n",
       "      <td>76.7275</td>\n",
       "      <td>27.1284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>truck</td>\n",
       "      <td>80.263</td>\n",
       "      <td>83.8066</td>\n",
       "      <td>89.8769</td>\n",
       "      <td>92.2465</td>\n",
       "      <td>87.247</td>\n",
       "      <td>84.2473</td>\n",
       "      <td>83.2474</td>\n",
       "      <td>87.247</td>\n",
       "      <td>88.3609</td>\n",
       "      <td>...</td>\n",
       "      <td>173.905</td>\n",
       "      <td>172.308</td>\n",
       "      <td>172.297</td>\n",
       "      <td>170.596</td>\n",
       "      <td>168.596</td>\n",
       "      <td>164.597</td>\n",
       "      <td>160.597</td>\n",
       "      <td>156.597</td>\n",
       "      <td>156.483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>truck</td>\n",
       "      <td>125.853</td>\n",
       "      <td>121.555</td>\n",
       "      <td>124.142</td>\n",
       "      <td>125.598</td>\n",
       "      <td>122.585</td>\n",
       "      <td>109.454</td>\n",
       "      <td>108.399</td>\n",
       "      <td>109.22</td>\n",
       "      <td>108.323</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4837</td>\n",
       "      <td>2.1847</td>\n",
       "      <td>4.0705</td>\n",
       "      <td>9.07</td>\n",
       "      <td>22.0687</td>\n",
       "      <td>40.0669</td>\n",
       "      <td>47.9521</td>\n",
       "      <td>49.066</td>\n",
       "      <td>50.0659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truck</td>\n",
       "      <td>167.966</td>\n",
       "      <td>148.458</td>\n",
       "      <td>122.005</td>\n",
       "      <td>87.7433</td>\n",
       "      <td>57.4814</td>\n",
       "      <td>49.2542</td>\n",
       "      <td>55.2876</td>\n",
       "      <td>59.7341</td>\n",
       "      <td>56.6635</td>\n",
       "      <td>...</td>\n",
       "      <td>96.4897</td>\n",
       "      <td>94.6362</td>\n",
       "      <td>93.1355</td>\n",
       "      <td>93.6085</td>\n",
       "      <td>93.4945</td>\n",
       "      <td>87.3471</td>\n",
       "      <td>78.6129</td>\n",
       "      <td>71.1236</td>\n",
       "      <td>65.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        0        1        2        3        4        5        6  \\\n",
       "0  truck  158.756   200.98  248.317  245.317  247.203  248.203  250.203   \n",
       "1  truck  147.931  130.922   123.11  152.324  161.039  191.824  242.378   \n",
       "2  truck   80.263  83.8066  89.8769  92.2465   87.247  84.2473  83.2474   \n",
       "3  truck  125.853  121.555  124.142  125.598  122.585  109.454  108.399   \n",
       "4  truck  167.966  148.458  122.005  87.7433  57.4814  49.2542  55.2876   \n",
       "\n",
       "         7        8    ...        1015     1016     1017     1018     1019  \\\n",
       "0  249.975  247.975    ...     236.824  235.824  235.824  235.824  234.824   \n",
       "1  252.975  253.747    ...     49.3927   47.795  35.0459  42.5397  87.0962   \n",
       "2   87.247  88.3609    ...     173.905  172.308  172.297  170.596  168.596   \n",
       "3   109.22  108.323    ...      1.4837   2.1847   4.0705     9.07  22.0687   \n",
       "4  59.7341  56.6635    ...     96.4897  94.6362  93.1355  93.6085  93.4945   \n",
       "\n",
       "      1020     1021     1022     1023 label_int  \n",
       "0  233.938  233.938  232.938  233.938         0  \n",
       "1  59.3179  72.4244  76.7275  27.1284         0  \n",
       "2  164.597  160.597  156.597  156.483         0  \n",
       "3  40.0669  47.9521   49.066  50.0659         0  \n",
       "4  87.3471  78.6129  71.1236    65.46         0  \n",
       "\n",
       "[5 rows x 1026 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {\n",
    "    'truck': 0,\n",
    "    'automobile': 1\n",
    "}\n",
    "df['label_int'] = [label_dict[x] for x in df.label]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('./clean-data/vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1024)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./clean-data/vehicles.csv', index_col=0)\n",
    "\n",
    "X = df.drop(['label', 'label_int'], axis=1).astype(np.float)\n",
    "y = df['label_int'].astype(np.int)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "We will pull out 10% of our samples to serve as a test set for our classifier. This will allow us to gauge the generalization performance of our different models given their different architectures. We will train each model on the training set that contains 90% of our samples. Because of the large training time, we will only train and test once for each architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "col_names = X.columns.values\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=64)\n",
    "for train_idx, test_idx in sss.split(X.values, y.values):\n",
    "    # X_train - 80% training attribute set\n",
    "    # X_test - 20% test attribute set\n",
    "    # y_train - 80% training labels\n",
    "    # y_test - 20% training labels\n",
    "    X_train, X_test = pd.DataFrame(X.values[train_idx], columns=col_names), pd.DataFrame(X.values[test_idx], columns=col_names)\n",
    "    y_train, y_test = pd.DataFrame(y.values[train_idx], columns=[\"label_int\"]), pd.DataFrame(y.values[test_idx], columns=[\"label_int\"])\n",
    "\n",
    "y_train, y_test = y_train.values.flatten(), y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Alex Krizhevsky, 2009: <a href=\"http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf\">Learning Multiple Layers of Features from Tiny Images</a>\n",
    "\n",
    "Face the Facts USA, 2013: <a href=\"https://www.facethefactsusa.org/facts/get-numbers-truck\">Get the numbers of that truck</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLEnv]",
   "language": "python",
   "name": "conda-env-MLEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
