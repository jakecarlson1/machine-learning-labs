{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6 - Wide and Deep Networks\n",
    "\n",
    "### Eric Smith and Jake Carlson\n",
    "\n",
    "## Introduction\n",
    "For this lab, we will again be examining the Global Terrorism Database maintained by the National Consortium for the Study of Terrorism and Responses to Terrorism (START) at the University of Maryland. We will be looking at attacks that happened in the United States over the whole time span of the data set, since it's creation in 1974.\n",
    "\n",
    "## Business Understanding\n",
    "\n",
    "### Motivations\n",
    "Protecting the United States from terror threats has been a major objective of the federal government. This is characterized by the founding of the Department of Homeland Security in 2001. But predicting when an attack will happen based on certain attributes is next to impossible. Attempting to train a model on the Global Terrorism Database to learn when terrorist attacks happen will result in a model that is over-trained on the GTD and will fail to predict any such attacks. Not to mention, such a system would have to be accompanied by a large-scale communication monitoring and processing system capable of feeding the model relevant inputs that exemplify a possible attack.\n",
    "\n",
    "Instead of trying to predict when an attack will happen, our goal is to create a model that can predict the cost associate with an individual attack. Immediately after an attack has happened, law enforcement can feed in information about the attack, such as the attack type, the number of people injured, and the target type, and they could receive an approximation of the amount of property damage dealt to their city. Such a model would allow city officials and law enforcement to estimate in real time how much an attack will cost their city. Knowing the estimated cost would enable city officials to determine if they need to request support from the federal government in a shorter timeframe. Furthermore, cities could plan their future budgets accordingly to incorporate funding in response to a terrorist attack.\n",
    "\n",
    "Cities have to submit requests to FEMA for non-disaster grants to aid in the prevention and response to terrorist activity. The Department of Homeland Security can also issue grants to aid in the prevention of terrorism. Grant policies start with Congress allocating funds for federal grants of this type. The Executive Branch provides input for how the policy should be implemented. Then grant issuing agencies develop their own policies for how to allocate grant money.\n",
    "\n",
    "Each state defines their own thresholds for when an attack is severe enough that they will ask for federal assistance. Our model will allow officials to immediately decide if they need to file for a federal grant. Smaller cities have lwoer thresholds and larger cities can handle higher costs before needing assistance.\n",
    "\n",
    "### Objectives\n",
    "Based on the characteristics of an attack, such as the target type and the date, we want to assign an estimated cost label to the entity. Because our system will be used to estimate the cost for local city governements, perfect classification of cost is not required. However, it is important that these estimations are accurate because a request for a grant will need to be formed and sent to the federal government.\n",
    "\n",
    "Based on the distribution of our classes we want to achieve an accuracy that is greater than the ratio of the majority class to the rest of the population. The class counts are given by:\n",
    "\n",
    "    Catastrophic (class 0): 4\n",
    "    Major (class 1): 88\n",
    "    Minor (class 2): 5871\n",
    "    Unknown (class 3): 1655\n",
    "\n",
    "The majority class is class 2, which constitutes 87% of the data set. We want to achieve a classification accuracy greater than this for our model to be useful.\n",
    "\n",
    "### Evaluation\n",
    "Because our majority class represents 77% of all the samples, we are aiming for a score higher than 77%. This would indicate our classifier is performing better than simply picking the majority class every time. We will use a custom score metric. This metric penalizes a property damage prediction that is less than the true value by a greater factor than predicting a damage value that is less than the true values. The idea here is that it would be bad if our model said the amount of money a city needed to request was less than the actual property damage extent, however, if more money was requested than is actually needed, it would be easier to make the adjustment if the larger value had already been approved. This corresponds to attempting to minimize values in the upper triangle of the confusion matrix as we move into prediction.\n",
    "\n",
    "We will use stratified 4-fold cross validation to ensure we are maintaining our class distribution in every training and test fold. We will only use four folds because our least represented class, the Catestrophic damage class, only has four instances. If we increased the number of folds, we would be training on data subsets that do not represent one of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_cost(y_true, y_pred):\n",
    "    score = 0\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        # Correct: 1\n",
    "        if y_pred[i] == y_true[i]:\n",
    "            score += 1\n",
    "        \n",
    "        # Too low (e.g. Minor predicted, Major actual): 0.25\n",
    "        # Class 0,1,2 when actual is unknown: 0.25\n",
    "        elif y_pred[i] > y_true[i] or y_true[i] == 3:\n",
    "            score += 0.25\n",
    "        \n",
    "        # Too high (e.g. Major predicted, minor actual): 0.75\n",
    "        # Unknown when actual is 0,1, or 2: 0.75\n",
    "        elif y_pred[i] < y_true[i] or y_pred[i] == 3:\n",
    "            score += 0.75\n",
    "\n",
    "    return score / len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Attributes\n",
    "Here is the list of attributes we will keep in our data set to use for classification.\n",
    "\n",
    "#### General Information\n",
    "- **iyear** (ordinal): The year the event occured in\n",
    "- **imonth** (ordinal): The month the event occured in\n",
    "- **iday** (ordinal): The day the event occured in\n",
    "- **extended** (binary): 1 if the incident was longer than 24 hours, 0 otherwise\n",
    "    - **resolution** (ordinal): The date an extended incident was resolved if *extended* is 1\n",
    "\n",
    "\n",
    "- **inclusion criteria** (binary): There are three inclusion criteria where a 1 indicates the event meets that criteria\n",
    "    - **crit1**: Political, economic, religious, or social goal\n",
    "    - **crit2**: Intention to coerce, intimidate, or publicize\n",
    "    - **crit3**: Outside international humanitarian law\n",
    "\n",
    "\n",
    "#### Location\n",
    "We will provide the name of the city to the model. An alternative method would be to train a unique logistic regression algorithm for each city where our system is deployed.\n",
    "- **city** (text): Name of the city in which the event occured\n",
    "- **vicinity** (nominal/binary): A 1 indicates the event occured in the immediate vicinity of *city*, 0 indicates the even occured in *city*\n",
    "- **latitude** (ratio): The latitude of the *city* in which the event occured\n",
    "- **longitude** (ratio): The longitude of the *city* in which the event occured\n",
    "\n",
    "#### Attack Type\n",
    "The most severe method of attack. This will be our class label. Although the original data set contains columns for three different attack types, the attack types are ranked by their severity. Many attacks only have one attack type. By removing the second and third attack types from our data set, we will still be predicting the most severe of the attack types.\n",
    "- **attacktype1** (ordinal): Most severe attack type\n",
    "\n",
    "- The attack types follow the following hierarchy:\n",
    "    1. Assassination\n",
    "    2. Armed Assault\n",
    "    3. Bombing/Explosion\n",
    "    4. Hijacking\n",
    "    5. Barricade Incident\n",
    "    6. Kidnapping\n",
    "    7. Facility/Infrastructure Attack \n",
    "    8. Unarmed Assault\n",
    "    9. Unknown\n",
    "\n",
    "\n",
    "- **suicide** (nominal/binary): A 1 indicates there was evidence the attacker did not make an effort to escape with their life\n",
    "\n",
    "#### Target Type\n",
    "We will only be considering the first target type of the attack. The set of target attributes is provided below:\n",
    "- **targtype1, targtype1_txt** (nominal): The general type of target from the following list:\n",
    "    1. Business\n",
    "    2. Government (General)\n",
    "    3. Police\n",
    "    4. Military\n",
    "    5. Abortion related\n",
    "    6. Airports and aircraft\n",
    "    7. Government (Diplomatic)\n",
    "    8. Educational institution\n",
    "    9. Food or water supply\n",
    "    10. Journalists and media\n",
    "    11. Maritime\n",
    "    12. NGO\n",
    "    13. Other\n",
    "    14. Private citizens and property\n",
    "    15. Religious figures and institutions\n",
    "    16. Telecommunication\n",
    "    17. Terrirists and non-state militias\n",
    "    18. Tourists\n",
    "    19. Transportation\n",
    "    20. Unknown\n",
    "    21. Utilities\n",
    "    22. Violent political parties\n",
    "    \n",
    "\n",
    "- **targsubtype1, targsubtype1_txt** (nominal): There are a number of subtypes for each of the above target types\n",
    "\n",
    "#### Perpetrator Information\n",
    "The data set provides information on up to three perpetrators if the attack was conducted by multiple groups. We will only be considering the first group, or the one decided to have the most responsibility for the attack.\n",
    "- **individual** (binary): A 1 indicates the individuals carrying out the attack are not affiliated with a terror organization\n",
    "- **nperps** (ratio): Indicates the total number of terrorists participating in the event\n",
    "- **nperpcap** (ratio): Number of perpatrators taken into custody\n",
    "- **claimed** (binary): A 1 indicates a person or group claimed responsibility for the attack\n",
    "- **claimmode** (nominal): Records the method the terror group used to claim responsibility for the attack. Can be one of the ten following categories:\n",
    "    1. Letter\n",
    "    2. Call (post-incident)\n",
    "    3. Call (pre-incident)\n",
    "    4. E-mail\n",
    "    5. Note left at scene\n",
    "    6. Video\n",
    "    7. Posted to website\n",
    "    8. Personal claim\n",
    "    9. Other\n",
    "    10. Unknown\n",
    "\n",
    "\n",
    "#### Casualties and Consequences\n",
    "- **nkill** (ratio): Records the number of confirmed kills for the incident\n",
    "- **nkillter** (ratio): Indicates the number of terrorists who were killed in the event\n",
    "- **nwound** (ratio): Indicates the number of people who sustained non-fatal injuries in the event\n",
    "- **nwoundte** (ratio): Indicates the number of terrorists who sustained non-lethal injuries\n",
    "- **property** (binary): A 1 indicates the event resulted in property damage. We will only select entities that resulted in property damage\n",
    "- **propextent** (ordinal): If *property* is a 1, this field records the extent of the property damage following the scheme:\n",
    "    <ol start='0'>\n",
    "        <li>Catastrophic (likely > \\$1 billion)</li>\n",
    "        <li>Major (likely > \\$1 million and < \\$1 billion)</li>\n",
    "        <li>Minor (likely < \\$1 million)</li>\n",
    "        <li>Unknown</li>\n",
    "    </ol>\n",
    "\n",
    "### Data Cleaning\n",
    "We will clean the data set so only the above attributes are present. We will subset our data to the events that resulted in property damage. We will then replace the elements in each column that are unknown with NaN, replace unknown cities with the most commonly attacked city in each country, along with the corresponding lattitude and longitude. The remaining empty values are replaced with the median for the column. We will then normalize all of the ratio columns and introduce a new attribute, dayn, that replaces the month and day attributes with a value that represents the day number the event occured on between 1 and 365. Finally, we use a label encoder to assign integer values to all of the categorical text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JakeCarlson/anaconda/envs/MLEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (6,63,79,94,96,114,115) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent maintained:  36.354092102123595 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iyear</th>\n",
       "      <th>extended</th>\n",
       "      <th>country_txt</th>\n",
       "      <th>city</th>\n",
       "      <th>vicinity</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crit1</th>\n",
       "      <th>crit2</th>\n",
       "      <th>crit3</th>\n",
       "      <th>...</th>\n",
       "      <th>nwoundte</th>\n",
       "      <th>propextent</th>\n",
       "      <th>ishostkid</th>\n",
       "      <th>nhostkid</th>\n",
       "      <th>nreleased</th>\n",
       "      <th>dayn</th>\n",
       "      <th>attacktype1_txt_int</th>\n",
       "      <th>targtype1_txt_int</th>\n",
       "      <th>country_txt_int</th>\n",
       "      <th>city_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>False</td>\n",
       "      <td>0.758239</td>\n",
       "      <td>0.161304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.095499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>False</td>\n",
       "      <td>0.758239</td>\n",
       "      <td>0.161304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>False</td>\n",
       "      <td>0.740602</td>\n",
       "      <td>0.150956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>Shanksville</td>\n",
       "      <td>True</td>\n",
       "      <td>0.751555</td>\n",
       "      <td>0.144956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.042810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>False</td>\n",
       "      <td>0.733236</td>\n",
       "      <td>0.452702</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>2281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    iyear  extended    country_txt           city  vicinity  latitude  \\\n",
       "3     0.0     False  United States  New York City     False  0.758239   \n",
       "4     0.0     False  United States  New York City     False  0.758239   \n",
       "5     0.0     False  United States      Arlington     False  0.740602   \n",
       "6     0.0     False  United States    Shanksville      True  0.751555   \n",
       "10    0.0     False          Italy        Palermo     False  0.733236   \n",
       "\n",
       "    longitude  crit1  crit2  crit3    ...     nwoundte  propextent ishostkid  \\\n",
       "3    0.161304   True   True   True    ...          0.0         0.0      True   \n",
       "4    0.161304   True   True   True    ...          0.0         0.0      True   \n",
       "5    0.150956   True   True   True    ...          0.0         0.0      True   \n",
       "6    0.144956   True   True   True    ...          0.0         0.0      True   \n",
       "10   0.452702   True   True   True    ...          0.0         2.0     False   \n",
       "\n",
       "    nhostkid  nreleased      dayn  attacktype1_txt_int  targtype1_txt_int  \\\n",
       "3   0.095499   0.000000  0.000000                    4                 13   \n",
       "4   0.063666   0.000000  0.000000                    4                 13   \n",
       "5   0.063666   0.000000  0.000000                    4                  6   \n",
       "6   0.042810   0.000000  0.000000                    4                 13   \n",
       "10  0.003293   0.001256  0.017857                    0                 12   \n",
       "\n",
       "    country_txt_int  city_int  \n",
       "3                99      2171  \n",
       "4                99      2171  \n",
       "5                99       183  \n",
       "6                99      2724  \n",
       "10               46      2281  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/After_911.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# drop rows without property damage or unknown city\n",
    "orig_len = df.shape[0]\n",
    "df = df[df['property'] == 1]\n",
    "df = df[df['city'] != \"Unknown\"]\n",
    "new_len = df.shape[0]\n",
    "print(\"Percent maintained: \", new_len/orig_len*100, \"%\")\n",
    "\n",
    "# select columns of interest\n",
    "df = df[['iyear', 'imonth', 'iday', 'extended', 'country_txt', 'city', 'vicinity',\n",
    "         'latitude', 'longitude', 'crit1', 'crit2', 'crit3', 'success', 'suicide',\n",
    "         'attacktype1_txt', 'targtype1_txt', 'individual', 'nperps', 'nperpcap', \n",
    "         'claimed', 'claimmode', 'nkill', 'nkillter', 'nwound', \n",
    "         'nwoundte', 'propextent', 'ishostkid', 'nhostkid', 'nreleased']]\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "logical_cols = ['extended', 'vicinity', 'crit1', 'crit2', 'crit3',\n",
    "                'success', 'suicide', 'individual', 'claimed', 'ishostkid']\n",
    "categorical_cols_txt = ['attacktype1_txt', 'targtype1_txt', 'country_txt', 'city']\n",
    "categorical_cols_int = ['claimmode']\n",
    "ratio_cols = ['latitude', 'longitude', 'nperps', 'nperpcap', 'nkill',\n",
    "              'nkillter', 'nwound', 'nwoundte', 'nhostkid', 'nreleased']\n",
    "\n",
    "# replace unknowns with nan\n",
    "logical_replace = dict((l, {-9:np.nan}) for l in ['claimed'])\n",
    "ratio_replace = dict((r, {-99:np.nan, -9:np.nan}) for r in ratio_cols)\n",
    "df.replace(to_replace=logical_replace, inplace=True)\n",
    "df.replace(to_replace=ratio_replace, inplace=True)\n",
    "\n",
    "# replace NA city with mode city for country\n",
    "df['city'] = df.groupby('country_txt')['city'].transform(lambda x: x.fillna(x.mode().iloc[0]))\n",
    "df['latitude'] = df.groupby('country_txt')['latitude'].transform(lambda x: x.fillna(x.mode().iloc[0]))\n",
    "df['longitude'] = df.groupby('country_txt')['longitude'].transform(lambda x: x.fillna(x.mode().iloc[0]))\n",
    "\n",
    "# replace NA's with median for col\n",
    "df.fillna(value=df.median(), inplace=True)\n",
    "\n",
    "# convert logical cols to bools\n",
    "for l in logical_cols:\n",
    "    df[l] = df[l].astype('bool')\n",
    "\n",
    "# normalize ratio cols\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "df[ratio_cols] = min_max_scaler.fit_transform(df[ratio_cols])\n",
    "\n",
    "# standardize date attributes\n",
    "# use year, month, and day to get day number in year\n",
    "day_list = []\n",
    "for r in df[['iyear', 'imonth', 'iday']].iterrows():\n",
    "    # fudge day 0 to 1\n",
    "    if r[1].iday == 0:\n",
    "        day_list.append(\n",
    "            datetime(r[1].iyear, r[1].imonth, 1).timetuple().tm_yday)\n",
    "    else:\n",
    "        day_list.append(\n",
    "            datetime(r[1].iyear, r[1].imonth, r[1].iday).timetuple().tm_yday)\n",
    "        \n",
    "df = df.assign(dayn=day_list)\n",
    "\n",
    "# drop month and day attributes\n",
    "df.drop(['imonth', 'iday'], axis=1, inplace=True)\n",
    "\n",
    "# normalize day number and year col\n",
    "df['iyear'] = df['iyear'].astype(np.float64)\n",
    "df['dayn'] = df['dayn'].astype(np.float64)\n",
    "df[['iyear', 'dayn']] = min_max_scaler.fit_transform(df[['iyear', 'dayn']])\n",
    "\n",
    "# convert categorical cols as ints\n",
    "for c in categorical_cols_int:\n",
    "    df[c] = df[c].astype(np.int64)\n",
    "\n",
    "encoders = {}\n",
    "# one-hot encode categorical cols\n",
    "for c in categorical_cols_txt:\n",
    "    encoders[c] = preprocessing.LabelEncoder()\n",
    "    df[c+'_int'] = encoders[c].fit_transform(df[c])\n",
    "    categorical_cols_int.append(c+'_int')\n",
    "\n",
    "# zero-index propextent\n",
    "df.propextent = df.propextent - 1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7618 entries, 3 to 20953\n",
      "Data columns (total 32 columns):\n",
      "iyear                  7618 non-null float64\n",
      "extended               7618 non-null bool\n",
      "country_txt            7618 non-null object\n",
      "city                   7618 non-null object\n",
      "vicinity               7618 non-null bool\n",
      "latitude               7618 non-null float64\n",
      "longitude              7618 non-null float64\n",
      "crit1                  7618 non-null bool\n",
      "crit2                  7618 non-null bool\n",
      "crit3                  7618 non-null bool\n",
      "success                7618 non-null bool\n",
      "suicide                7618 non-null bool\n",
      "attacktype1_txt        7618 non-null object\n",
      "targtype1_txt          7618 non-null object\n",
      "individual             7618 non-null bool\n",
      "nperps                 7618 non-null float64\n",
      "nperpcap               7618 non-null float64\n",
      "claimed                7618 non-null bool\n",
      "claimmode              7618 non-null int64\n",
      "nkill                  7618 non-null float64\n",
      "nkillter               7618 non-null float64\n",
      "nwound                 7618 non-null float64\n",
      "nwoundte               7618 non-null float64\n",
      "propextent             7618 non-null float64\n",
      "ishostkid              7618 non-null bool\n",
      "nhostkid               7618 non-null float64\n",
      "nreleased              7618 non-null float64\n",
      "dayn                   7618 non-null float64\n",
      "attacktype1_txt_int    7618 non-null int64\n",
      "targtype1_txt_int      7618 non-null int64\n",
      "country_txt_int        7618 non-null int64\n",
      "city_int               7618 non-null int64\n",
      "dtypes: bool(10), float64(13), int64(5), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save full clean data set\n",
    "df.to_csv('./clean-data/After_911_clean.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossed Columns\n",
    "We will create several crossed columns to make the data set wider. This will help our model with memorization of the training data. We will cross attack type with target type, city, and country. It is our understanding that cercain types of attacks occur more frequently in different cities. We also think that certain target types will attract more attacks of a certain type. By creating crossed columns, we make this relationship explicit so that the model will learn this relationship on our small data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iyear</th>\n",
       "      <th>extended</th>\n",
       "      <th>country_txt</th>\n",
       "      <th>city</th>\n",
       "      <th>vicinity</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crit1</th>\n",
       "      <th>crit2</th>\n",
       "      <th>crit3</th>\n",
       "      <th>...</th>\n",
       "      <th>nwoundte</th>\n",
       "      <th>propextent</th>\n",
       "      <th>ishostkid</th>\n",
       "      <th>nhostkid</th>\n",
       "      <th>nreleased</th>\n",
       "      <th>dayn</th>\n",
       "      <th>attacktype1_txt_int</th>\n",
       "      <th>targtype1_txt_int</th>\n",
       "      <th>country_txt_int</th>\n",
       "      <th>city_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>False</td>\n",
       "      <td>0.758239</td>\n",
       "      <td>0.161304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.095499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>False</td>\n",
       "      <td>0.758239</td>\n",
       "      <td>0.161304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>False</td>\n",
       "      <td>0.740602</td>\n",
       "      <td>0.150956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>Shanksville</td>\n",
       "      <td>True</td>\n",
       "      <td>0.751555</td>\n",
       "      <td>0.144956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.042810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>False</td>\n",
       "      <td>0.733236</td>\n",
       "      <td>0.452702</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>2281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    iyear  extended    country_txt           city  vicinity  latitude  \\\n",
       "3     0.0     False  United States  New York City     False  0.758239   \n",
       "4     0.0     False  United States  New York City     False  0.758239   \n",
       "5     0.0     False  United States      Arlington     False  0.740602   \n",
       "6     0.0     False  United States    Shanksville      True  0.751555   \n",
       "10    0.0     False          Italy        Palermo     False  0.733236   \n",
       "\n",
       "    longitude  crit1  crit2  crit3    ...     nwoundte  propextent ishostkid  \\\n",
       "3    0.161304   True   True   True    ...          0.0         0.0      True   \n",
       "4    0.161304   True   True   True    ...          0.0         0.0      True   \n",
       "5    0.150956   True   True   True    ...          0.0         0.0      True   \n",
       "6    0.144956   True   True   True    ...          0.0         0.0      True   \n",
       "10   0.452702   True   True   True    ...          0.0         2.0     False   \n",
       "\n",
       "    nhostkid  nreleased      dayn  attacktype1_txt_int  targtype1_txt_int  \\\n",
       "3   0.095499   0.000000  0.000000                    4                 13   \n",
       "4   0.063666   0.000000  0.000000                    4                 13   \n",
       "5   0.063666   0.000000  0.000000                    4                  6   \n",
       "6   0.042810   0.000000  0.000000                    4                 13   \n",
       "10  0.003293   0.001256  0.017857                    0                 12   \n",
       "\n",
       "    country_txt_int  city_int  \n",
       "3                99      2171  \n",
       "4                99      2171  \n",
       "5                99       183  \n",
       "6                99      2724  \n",
       "10               46      2281  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./clean-data/After_911_clean.csv', index_col=0)\n",
    "\n",
    "logical_cols = ['extended', 'vicinity', 'crit1', 'crit2', 'crit3',\n",
    "                'success', 'suicide', 'individual', 'claimed', 'ishostkid']\n",
    "categorical_cols_txt = ['attacktype1_txt', 'targtype1_txt', 'country_txt', 'city']\n",
    "categorical_cols_int = ['claimmode'] + [x+'_int' for x in categorical_cols_txt]\n",
    "ratio_cols = ['iyear', 'latitude', 'longitude', 'nperps', 'nperpcap', 'nkill',\n",
    "              'nkillter', 'nwound', 'nwoundte', 'nhostkid', 'nreleased', 'dayn']\n",
    "feature_cols = logical_cols + categorical_cols_int + ratio_cols\n",
    "\n",
    "y = df['propextent']\n",
    "X = df.drop(['propextent'], axis=1)\n",
    "y_ints = y.values\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7618 entries, 3 to 20953\n",
      "Data columns (total 32 columns):\n",
      "iyear                  7618 non-null float64\n",
      "extended               7618 non-null bool\n",
      "country_txt            7618 non-null object\n",
      "city                   7618 non-null object\n",
      "vicinity               7618 non-null bool\n",
      "latitude               7618 non-null float64\n",
      "longitude              7618 non-null float64\n",
      "crit1                  7618 non-null bool\n",
      "crit2                  7618 non-null bool\n",
      "crit3                  7618 non-null bool\n",
      "success                7618 non-null bool\n",
      "suicide                7618 non-null bool\n",
      "attacktype1_txt        7618 non-null object\n",
      "targtype1_txt          7618 non-null object\n",
      "individual             7618 non-null bool\n",
      "nperps                 7618 non-null float64\n",
      "nperpcap               7618 non-null float64\n",
      "claimed                7618 non-null bool\n",
      "claimmode              7618 non-null int64\n",
      "nkill                  7618 non-null float64\n",
      "nkillter               7618 non-null float64\n",
      "nwound                 7618 non-null float64\n",
      "nwoundte               7618 non-null float64\n",
      "propextent             7618 non-null float64\n",
      "ishostkid              7618 non-null bool\n",
      "nhostkid               7618 non-null float64\n",
      "nreleased              7618 non-null float64\n",
      "dayn                   7618 non-null float64\n",
      "attacktype1_txt_int    7618 non-null int64\n",
      "targtype1_txt_int      7618 non-null int64\n",
      "country_txt_int        7618 non-null int64\n",
      "city_int               7618 non-null int64\n",
      "dtypes: bool(10), float64(13), int64(5), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set\n",
    "We will pull out 10% of our samples to serve as a validation set for our classifier. This will allow us to gauge the generalization performance of our different models given their different architectures after we run our 4-fold cross validation. Before running prediction on the validation set, we will train our models on all of the instances in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "col_names = X.columns.values\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=4, test_size=0.1, random_state=64)\n",
    "for train_idx, test_idx in sss.split(X.values, y.values):\n",
    "    # X_train - 80% training attribute set\n",
    "    # X_test - 20% test attribute set\n",
    "    # y_train - 80% training labels\n",
    "    # y_test - 20% training labels\n",
    "    X_train, X_test = pd.DataFrame(X.values[train_idx], columns=col_names), pd.DataFrame(X.values[test_idx], columns=col_names)\n",
    "    y_train, y_test = pd.DataFrame(y.values[train_idx], columns=[\"propextent\"]), pd.DataFrame(y.values[test_idx], columns=[\"propextent\"])\n",
    "\n",
    "y_train, y_test = y_train.values.flatten(), y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "### First Deep Architecture\n",
    "The first architecture we propose uses three layers on the deep side of the network. We use dropout inbetween these layers to prevent overfitting to the training set. We use 128 neurons in the first layer, 64 in the second, and 16 in the third. As the weights are updated, 20% of the neurons will not be updated in the first layer, and 40% of the neruons will not be updated in the second layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1    0    0    0]\n",
      " [   0    2   16    2]\n",
      " [   0   73 1171   77]\n",
      " [   0   49  252   72]] => 0.8161807580174927\n",
      "[[   1    0    0    0]\n",
      " [   0   14    6    0]\n",
      " [   0   29 1226   66]\n",
      " [   0   17  122  233]] => 0.9034422403733956\n",
      "[[   1    0    0    0]\n",
      " [   0   16    2    2]\n",
      " [   0   45 1209   67]\n",
      " [   0   14  130  228]] => 0.8993582263710619\n",
      "[[   1    0    0    0]\n",
      " [   0   14    4    1]\n",
      " [   0   46 1222   53]\n",
      " [   0   18  125  229]] => 0.9052831290134268\n",
      "[0.8161807580174927, 0.9034422403733956, 0.8993582263710619, 0.9052831290134268]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input, Dropout\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "cross_columns = [['attacktype1_txt','targtype1_txt'],\n",
    "                 ['attacktype1_txt','city'],\n",
    "                 ['attacktype1_txt','country_txt']]\n",
    "\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_branch_outputs = []\n",
    "\n",
    "for cols in cross_columns:\n",
    "    # encode crossed columns as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "\n",
    "    # create crossed labels\n",
    "    X_crossed_train = X_train[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    X_crossed_test = X_test[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "    enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "    X_crossed_train = enc.transform(X_crossed_train)\n",
    "    X_crossed_test = enc.transform(X_crossed_test)\n",
    "    X_ints_train.append( X_crossed_train )\n",
    "    X_ints_test.append( X_crossed_test )\n",
    "\n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32',name = '_'.join(cols))\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "\n",
    "wide_branch = concatenate(all_branch_outputs)\n",
    "wide_branch = Dense(units=16,activation='relu')(wide_branch)\n",
    "\n",
    "all_branch_outputs = []\n",
    "# add in the embeddings\n",
    "for col in categorical_cols_int:\n",
    "    # encode as ints for the embedding\n",
    "    X_ints_train.append( X_train[col].values )\n",
    "    X_ints_test.append( X_test[col].values )\n",
    "\n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "\n",
    "# also get a dense branch of the ratio features\n",
    "all_inputs.append(Input(shape=(X_train[feature_cols].values.shape[1],),sparse=False))\n",
    "x = Dense(units=20, activation='relu', name=\"numeric\")(all_inputs[-1])\n",
    "all_branch_outputs.append( x )\n",
    "\n",
    "# merge the branches together\n",
    "deep_branch = concatenate(all_branch_outputs)\n",
    "deep_branch = Dense(units=128,activation='relu')(deep_branch)\n",
    "deep_branch = Dropout(0.2, seed=32)(deep_branch)\n",
    "deep_branch = Dense(units=64,activation='relu')(deep_branch)\n",
    "deep_branch = Dropout(0.4, seed=32)(deep_branch)\n",
    "deep_branch = Dense(units=16,activation='relu')(deep_branch)\n",
    "\n",
    "final_branch = concatenate([wide_branch, deep_branch])\n",
    "final_branch = Dense(units=16, activation='relu')(final_branch)\n",
    "final_branch = Dense(units=4,activation='softmax')(final_branch)\n",
    "\n",
    "X_train_final = X_ints_train\n",
    "X_train_final.append(X_train[feature_cols].values)\n",
    "\n",
    "class_weight = {\n",
    "    0: 1,\n",
    "    1: 4,\n",
    "    2: 0.1,\n",
    "    3: 0.08\n",
    "}\n",
    "\n",
    "costs = []\n",
    "kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=64)\n",
    "for train_idx, test_idx in kfold.split(X_train[feature_cols], y_train):\n",
    "    # build train and test samples from crossed cols and feature cols\n",
    "    X_train_temp = [X[train_idx] for X in X_train_final]\n",
    "    y_train_temp = y_train[train_idx]\n",
    "    X_test_temp = [X[test_idx] for X in X_train_final]\n",
    "    y_test_temp = y_train[test_idx]\n",
    "    \n",
    "    # rebuild model\n",
    "    model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "    model.compile(optimizer='adagrad',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # fit on train and predict on test\n",
    "    model.fit(X_train_temp, y_train_temp, class_weight=class_weight, epochs=20, batch_size=32, verbose=0)\n",
    "    pred = np.argmax(model.predict(X_test_temp), axis=1)\n",
    "    \n",
    "    # take cost\n",
    "    c = custom_cost(y_test_temp, pred)\n",
    "    costs.append(c)\n",
    "    \n",
    "    # print confusion matrix\n",
    "    print(confusion_matrix(y_test_temp,pred), \"=>\", c)\n",
    "\n",
    "print(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   5   2]\n",
      " [ 94 456  37]\n",
      " [ 34  95  37]]\n",
      "0.7988845144356955\n"
     ]
    }
   ],
   "source": [
    "X_test_final = X_ints_test\n",
    "X_test_final.append(X_test[feature_cols].values)\n",
    "\n",
    "model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train_final, y_train, class_weight=class_weight, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "pred = np.argmax(model.predict(X_test_final), axis=1)\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(custom_cost(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model_1 = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs well on our validation set. We are able to beat our score goal of 0.77. Because we are trying to minimize values in the upper triangle of the confusion matrix, we are using class weights that pull values to the left. This resulted in a lot of events that resulted in Minor property damage being classified as resulting in Major damage. Our class imbalance is working against us as it is difficult to learn what events with Major damage look like. We are unable to identify a majority of the instances that result in Major damage.\n",
    "\n",
    "### Second Deep Architecture\n",
    "In this architecture, we will use two layers in the deep branch. The first will have 64 neurons and the second will have 16. This is a simpler architecture than the first one presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    0    0]\n",
      " [   0    2   18    0]\n",
      " [   0  143 1161   17]\n",
      " [   0   77  282   14]] => 0.8064139941690962\n",
      "[[   0    1    0    0]\n",
      " [   0   14    6    0]\n",
      " [   0   33 1247   41]\n",
      " [   0   61  161  150]] => 0.8770420070011669\n",
      "[[   0    1    0    0]\n",
      " [   0   17    2    1]\n",
      " [   0   28 1225   68]\n",
      " [   0   21  154  197]] => 0.8878354725787632\n",
      "[[   0    1    0    0]\n",
      " [   0   16    2    1]\n",
      " [   0   40 1224   57]\n",
      " [   0   22  130  220]] => 0.9009048453006422\n",
      "[0.8064139941690962, 0.8770420070011669, 0.8878354725787632, 0.9009048453006422]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cross_columns = [['attacktype1_txt','targtype1_txt'],\n",
    "                 ['attacktype1_txt','city'],\n",
    "                 ['attacktype1_txt','country_txt']]\n",
    "\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_branch_outputs = []\n",
    "\n",
    "for cols in cross_columns:\n",
    "    # encode crossed columns as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "\n",
    "    # create crossed labels\n",
    "    X_crossed_train = X_train[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    X_crossed_test = X_test[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "    enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "    X_crossed_train = enc.transform(X_crossed_train)\n",
    "    X_crossed_test = enc.transform(X_crossed_test)\n",
    "    X_ints_train.append( X_crossed_train )\n",
    "    X_ints_test.append( X_crossed_test )\n",
    "\n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32',name = '_'.join(cols))\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "\n",
    "wide_branch = concatenate(all_branch_outputs)\n",
    "wide_branch = Dense(units=16,activation='relu')(wide_branch)\n",
    "\n",
    "all_branch_outputs = []\n",
    "# add in the embeddings\n",
    "for col in categorical_cols_int:\n",
    "    # encode as ints for the embedding\n",
    "    X_ints_train.append( X_train[col].values )\n",
    "    X_ints_test.append( X_test[col].values )\n",
    "\n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "\n",
    "# also get a dense branch of the ratio features\n",
    "all_inputs.append(Input(shape=(X_train[feature_cols].values.shape[1],),sparse=False))\n",
    "x = Dense(units=20, activation='relu', name=\"numeric\")(all_inputs[-1])\n",
    "all_branch_outputs.append( x )\n",
    "\n",
    "# merge the branches together\n",
    "deep_branch = concatenate(all_branch_outputs)\n",
    "deep_branch = Dense(units=64,activation='relu')(deep_branch)\n",
    "deep_branch = Dense(units=16,activation='relu')(deep_branch)\n",
    "\n",
    "final_branch = concatenate([wide_branch, deep_branch])\n",
    "final_branch = Dense(units=16, activation='relu')(final_branch)\n",
    "final_branch = Dense(units=4,activation='softmax')(final_branch)\n",
    "\n",
    "X_train_final = X_ints_train\n",
    "X_train_final.append(X_train[feature_cols].values)\n",
    "\n",
    "class_weight = {\n",
    "    0: 1,\n",
    "    1: 4,\n",
    "    2: 0.1,\n",
    "    3: 0.08\n",
    "}\n",
    "\n",
    "costs = []\n",
    "kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=64)\n",
    "for train_idx, test_idx in kfold.split(X_train[feature_cols], y_train):\n",
    "    # build train and test samples from crossed cols and feature cols\n",
    "    X_train_temp = [X[train_idx] for X in X_train_final]\n",
    "    y_train_temp = y_train[train_idx]\n",
    "    X_test_temp = [X[test_idx] for X in X_train_final]\n",
    "    y_test_temp = y_train[test_idx]\n",
    "    \n",
    "    # rebuild model\n",
    "    model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "    model.compile(optimizer='adagrad',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # fit on train and predict on test\n",
    "    model.fit(X_train_temp, y_train_temp, class_weight=class_weight, epochs=10, batch_size=32, verbose=0)\n",
    "    pred = np.argmax(model.predict(X_test_temp), axis=1)\n",
    "    \n",
    "    # take cost\n",
    "    c = custom_cost(y_test_temp, pred)\n",
    "    costs.append(c)\n",
    "    \n",
    "    # print confusion matrix\n",
    "    print(confusion_matrix(y_test_temp,pred), \"=>\", c)\n",
    "\n",
    "print(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4   4   1]\n",
      " [115 410  62]\n",
      " [ 41  85  40]]\n",
      "0.7723097112860893\n"
     ]
    }
   ],
   "source": [
    "X_test_final = X_ints_test\n",
    "X_test_final.append(X_test[feature_cols].values)\n",
    "\n",
    "model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train_final, y_train, class_weight=class_weight, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "pred = np.argmax(model.predict(X_test_final), axis=1)\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(custom_cost(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation is also able to beat our score goal, however it does not perform as well on the validation set. We are able to identify an additional instance of Major damage, but at the extent of missing more instances of minor damage. Therefore, we will move forward using our first network architecture.\n",
    "\n",
    "### Multi-Layer Perceptron\n",
    "We will now train a standard multi-layer perceptron on our data set to see how it compares to our wide and deep network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "sk_mlp = MLPClassifier(hidden_layer_sizes=(100,), \n",
    "                       solver='lbfgs', \n",
    "                       learning_rate_init=0.01, \n",
    "                       max_iter=120, \n",
    "                       random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    1    0]\n",
      " [   0    0   20    0]\n",
      " [   1    0 1320    0]\n",
      " [   1    0  372    0]] => 0.8275510204081633\n",
      "[[   0    0    1    0]\n",
      " [   0    0   20    0]\n",
      " [   1    0 1320    0]\n",
      " [   1    0  371    0]] => 0.8278879813302217\n",
      "[[   0    0    1    0]\n",
      " [   0    0   20    0]\n",
      " [   2    0 1319    0]\n",
      " [   4    0  368    0]] => 0.8277421236872812\n",
      "[[   0    0    1    0]\n",
      " [   0    0   19    0]\n",
      " [   2    0 1319    0]\n",
      " [   2    0  370    0]] => 0.8280793928779918\n",
      "[0.8275510204081633, 0.8278879813302217, 0.8277421236872812, 0.8280793928779918]\n"
     ]
    }
   ],
   "source": [
    "costs = []\n",
    "kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=64)\n",
    "for train_idx, test_idx in kfold.split(X_train[feature_cols], y_train):\n",
    "    # fit on train and predict on test\n",
    "    sk_mlp.fit(X_train[feature_cols].values[train_idx], y_train[train_idx])\n",
    "    pred_sk = sk_mlp.predict(X_train[feature_cols].values[test_idx])\n",
    "    \n",
    "    # take cost\n",
    "    c = custom_cost(y_train[test_idx], pred_sk)\n",
    "    costs.append(c)\n",
    "    \n",
    "    # print confusion matrix\n",
    "    print(confusion_matrix(y_train[test_idx],pred_sk), \"=>\", c)\n",
    "\n",
    "print(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   5   2]\n",
      " [ 94 456  37]\n",
      " [ 34  95  37]]\n",
      "0.7988845144356955\n"
     ]
    }
   ],
   "source": [
    "sk_mlp.fit(X_train[feature_cols], y_train)\n",
    "pred_sk = sk_mlp.predict(X_test[feature_cols])\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(custom_cost(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the MLP is able to score higher based on our custom cost measure, however, almost every prediciton falls under the Minor damage class. This indicates that the model has learn to simply predict Minor damage every time. TO get a better idea of the differences between the two models, we will use the receiver operating characteristic to visualize the true and false positive rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYDAYHExQMBgMBoPD/wNMJQAlRTKS1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134b6c358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "K = 4\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "pred = model_1.predict(X_test_final)\n",
    "pred_sk = sk_mlp.predict_proba(X_test[feature_cols])\n",
    "\n",
    "perclass_mean_tpr = 0.0\n",
    "roc_auc = 0\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "# get the mean fpr and tpr, per class\n",
    "for j in classes[1:]:\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,\n",
    "                                     pred[:,int(j)],\n",
    "                                     pos_label=j)\n",
    "    \n",
    "    perclass_mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    perclass_mean_tpr[0] = 0.0\n",
    "    roc_auc += auc(fpr, tpr)\n",
    "\n",
    "perclass_mean_tpr /= len(classes)\n",
    "roc_auc /= len(classes)\n",
    "mean_tpr += perclass_mean_tpr\n",
    "plt.plot(mean_fpr,perclass_mean_tpr,'--',lw=1,label='Mean Class ROC Custom (area = %0.2f)'\n",
    "               % (roc_auc))\n",
    "\n",
    "perclass_mean_tpr = 0.0\n",
    "roc_auc = 0\n",
    "\n",
    "# get the mean fpr and tpr, per class\n",
    "for j in classes[1:]:\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,\n",
    "                                     pred_sk[:,int(j)],\n",
    "                                     pos_label=j)\n",
    "    \n",
    "    perclass_mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    perclass_mean_tpr[0] = 0.0\n",
    "    roc_auc += auc(fpr, tpr)\n",
    "\n",
    "perclass_mean_tpr /= len(classes)\n",
    "roc_auc /= len(classes)\n",
    "mean_tpr += perclass_mean_tpr\n",
    "plt.plot(mean_fpr,perclass_mean_tpr,'--',lw=1,label='Mean Class ROC Sklearn (area = %0.2f)'\n",
    "               % (roc_auc))\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Macro Average Receiver Operating Characteristic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our network is able to achieve a higher true positive rate than scikit-learn. The larger area under the curve for our model reinforces that our model is able to learn more from our training data and generalizes better to the validation set. Moreover, the scikit-learn implementation ROC curve is very close to a diagonal from (0, 0) to (1, 1) indicating it is performing close to a random chance classifier. Therefore, our wide and deep network outperforms this simple multi-layer perceptron.\n",
    "\n",
    "## Weight Visualization\n",
    "We will pull out the embedding weights for the various columns and crossed coulmns to see what cetegories are most important for prediction. These will be the categorical features that have the most weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claimmode\n",
      "attacktype1_txt_int\n",
      "targtype1_txt_int\n",
      "country_txt_int\n",
      "city_int\n",
      "embedding_28\n",
      "embedding_29\n",
      "embedding_30\n",
      "embedding_31\n",
      "embedding_32\n",
      "input_4\n",
      "flatten_28\n",
      "flatten_29\n",
      "flatten_30\n",
      "flatten_31\n",
      "flatten_32\n",
      "numeric\n",
      "concatenate_11\n",
      "attacktype1_txt_targtype1_txt\n",
      "attacktype1_txt_city\n",
      "attacktype1_txt_country_txt\n",
      "dense_22\n",
      "embedding_25\n",
      "embedding_26\n",
      "embedding_27\n",
      "dropout_7\n",
      "flatten_25\n",
      "flatten_26\n",
      "flatten_27\n",
      "dense_23\n",
      "concatenate_10\n",
      "dropout_8\n",
      "dense_21\n",
      "dense_24\n",
      "concatenate_12\n",
      "dense_25\n",
      "dense_26\n"
     ]
    }
   ],
   "source": [
    "for l in model_1.layers:\n",
    "    print(l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLEnv]",
   "language": "python",
   "name": "conda-env-MLEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
