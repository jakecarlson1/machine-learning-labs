{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6 - Wide and Deep Networks\n",
    "\n",
    "### Eric Smith and Jake Carlson\n",
    "\n",
    "## Introduction\n",
    "For this lab, we will again be examining the Global Terrorism Database maintained by the National Consortium for the Study of Terrorism and Responses to Terrorism (START) at the University of Maryland. We will be looking at attacks that happened in the United States over the whole time span of the data set, since it's creation in 1974.\n",
    "\n",
    "## Business Understanding\n",
    "\n",
    "### Motivations\n",
    "Protecting the United States from terror threats has been a major objective of the federal government. This is characterized by the founding of the Department of Homeland Security in 2001. But predicting when an attack will happen based on certain attributes is next to impossible. Attempting to train a model on the Global Terrorism Database to learn when terrorist attacks happen will result in a model that is over-trained on the GTD and will fail to predict any such attacks. Not to mention, such a system would have to be accompanied by a large-scale communication monitoring and processing system capable of feeding the model relevant inputs that exemplify a possible attack.\n",
    "\n",
    "Instead of trying to predict when an attack will happen, our goal is to create a model that can predict the cost associate with an individual attack. Immediately after an attack has happened, law enforcement can feed in information about the attack, such as the attack type, the number of people injured, and the target type, and they could receive an approximation of the amount of property damage dealt to their city. Such a model would allow city officials and law enforcement to estimate in real time how much an attack will cost their city. Knowing the estimated cost would enable city officials to determine if they need to request support from the federal government in a shorter timeframe. Furthermore, cities could plan their future budgets accordingly to incorporate funding in response to a terrorist attack.\n",
    "\n",
    "Cities have to submit requests to FEMA for non-disaster grants to aid in the prevention and response to terrorist activity. The Department of Homeland Security can also issue grants to aid in the prevention of terrorism. Grant policies start with Congress allocating funds for federal grants of this type. The Executive Branch provides input for how the policy should be implemented. Then grant issuing agencies develop their own policies for how to allocate grant money.\n",
    "\n",
    "Each state defines their own thresholds for when an attack is severe enough that they will ask for federal assistance. Our model will allow officials to immediately decide if they need to file for a federal grant. Smaller cities have lwoer thresholds and larger cities can handle higher costs before needing assistance.\n",
    "\n",
    "### Objectives\n",
    "Based on the characteristics of an attack, such as the target type and the date, we want to assign an estimated cost label to the entity. Because our system will be used to estimate the cost for local city governements, perfect classification of cost is not required. However, it is important that these estimations are accurate because a request for a grant will need to be formed and sent to the federal government.\n",
    "\n",
    "Based on the distribution of our classes we want to achieve an accuracy that is greater than the ratio of the majority class to the rest of the population. The class counts are given by:\n",
    "\n",
    "    Catastrophic (class 0): 4\n",
    "    Major (class 1): 88\n",
    "    Minor (class 2): 5871\n",
    "    Unknown (class 3): 1655\n",
    "\n",
    "The majority class is class 2, which constitutes 87% of the data set. We want to achieve a classification accuracy greater than this for our model to be useful.\n",
    "\n",
    "### Evaluation ** REDO\n",
    "Because we are predicting the group that conducted the attack, it would be an issue if we predicted the wrong group. Law enforcement could waste time and resources following the incorrect prediction and the perpetrators would have more time to get away or plan another attack. We will evaluate our model using the precision score in order to minimize the false positive rate. We will use macro precision so all of the groups are weighted equally.\n",
    "\n",
    "Because some of the groups are over-represented, we will use stratified 10-fold cross validation so the classes in each fold match the distribution of the original data set. Running training and testing ten times will also allow us to be confident in the generalization performance of the model.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "### Attributes\n",
    "Here is the list of attributes we will keep in our data set to use for classification.\n",
    "\n",
    "#### General Information\n",
    "- **iyear** (ordinal): The year the event occured in\n",
    "- **imonth** (ordinal): The month the event occured in\n",
    "- **iday** (ordinal): The day the event occured in\n",
    "- **extended** (binary): 1 if the incident was longer than 24 hours, 0 otherwise\n",
    "    - **resolution** (ordinal): The date an extended incident was resolved if *extended* is 1\n",
    "\n",
    "\n",
    "- **inclusion criteria** (binary): There are three inclusion criteria where a 1 indicates the event meets that criteria\n",
    "    - **crit1**: Political, economic, religious, or social goal\n",
    "    - **crit2**: Intention to coerce, intimidate, or publicize\n",
    "    - **crit3**: Outside international humanitarian law\n",
    "\n",
    "\n",
    "#### Location\n",
    "We will provide the name of the city to the model. An alternative method would be to train a unique logistic regression algorithm for each city where our system is deployed.\n",
    "- **city** (text): Name of the city in which the event occured\n",
    "- **vicinity** (nominal/binary): A 1 indicates the event occured in the immediate vicinity of *city*, 0 indicates the even occured in *city*\n",
    "- **latitude** (ratio): The latitude of the *city* in which the event occured\n",
    "- **longitude** (ratio): The longitude of the *city* in which the event occured\n",
    "\n",
    "#### Attack Type\n",
    "The most severe method of attack. This will be our class label. Although the original data set contains columns for three different attack types, the attack types are ranked by their severity. Many attacks only have one attack type. By removing the second and third attack types from our data set, we will still be predicting the most severe of the attack types.\n",
    "- **attacktype1** (ordinal): Most severe attack type\n",
    "\n",
    "- The attack types follow the following hierarchy:\n",
    "    1. Assassination\n",
    "    2. Armed Assault\n",
    "    3. Bombing/Explosion\n",
    "    4. Hijacking\n",
    "    5. Barricade Incident\n",
    "    6. Kidnapping\n",
    "    7. Facility/Infrastructure Attack \n",
    "    8. Unarmed Assault\n",
    "    9. Unknown\n",
    "\n",
    "\n",
    "- **suicide** (nominal/binary): A 1 indicates there was evidence the attacker did not make an effort to escape with their life\n",
    "\n",
    "#### Target Type\n",
    "We will only be considering the first target type of the attack. The set of target attributes is provided below:\n",
    "- **targtype1, targtype1_txt** (nominal): The general type of target from the following list:\n",
    "    1. Business\n",
    "    2. Government (General)\n",
    "    3. Police\n",
    "    4. Military\n",
    "    5. Abortion related\n",
    "    6. Airports and aircraft\n",
    "    7. Government (Diplomatic)\n",
    "    8. Educational institution\n",
    "    9. Food or water supply\n",
    "    10. Journalists and media\n",
    "    11. Maritime\n",
    "    12. NGO\n",
    "    13. Other\n",
    "    14. Private citizens and property\n",
    "    15. Religious figures and institutions\n",
    "    16. Telecommunication\n",
    "    17. Terrirists and non-state militias\n",
    "    18. Tourists\n",
    "    19. Transportation\n",
    "    20. Unknown\n",
    "    21. Utilities\n",
    "    22. Violent political parties\n",
    "    \n",
    "\n",
    "- **targsubtype1, targsubtype1_txt** (nominal): There are a number of subtypes for each of the above target types\n",
    "\n",
    "#### Perpetrator Information\n",
    "The data set provides information on up to three perpetrators if the attack was conducted by multiple groups. We will only be considering the first group, or the one decided to have the most responsibility for the attack.\n",
    "- **individual** (binary): A 1 indicates the individuals carrying out the attack are not affiliated with a terror organization\n",
    "- **nperps** (ratio): Indicates the total number of terrorists participating in the event\n",
    "- **nperpcap** (ratio): Number of perpatrators taken into custody\n",
    "- **claimed** (binary): A 1 indicates a person or group claimed responsibility for the attack\n",
    "- **claimmode** (nominal): Records the method the terror group used to claim responsibility for the attack. Can be one of the ten following categories:\n",
    "    1. Letter\n",
    "    2. Call (post-incident)\n",
    "    3. Call (pre-incident)\n",
    "    4. E-mail\n",
    "    5. Note left at scene\n",
    "    6. Video\n",
    "    7. Posted to website\n",
    "    8. Personal claim\n",
    "    9. Other\n",
    "    10. Unknown\n",
    "\n",
    "\n",
    "#### Casualties and Consequences\n",
    "- **nkill** (ratio): Records the number of confirmed kills for the incident\n",
    "- **nkillter** (ratio): Indicates the number of terrorists who were killed in the event\n",
    "- **nwound** (ratio): Indicates the number of people who sustained non-fatal injuries in the event\n",
    "- **nwoundte** (ratio): Indicates the number of terrorists who sustained non-lethal injuries\n",
    "- **property** (binary): A 1 indicates the event resulted in property damage. We will only select entities that resulted in property damage\n",
    "- **propextent** (ordinal): If *property* is a 1, this field records the extent of the property damage following the scheme:\n",
    "    <ol start='0'>\n",
    "        <li>Catastrophic (likely > \\$1 billion)</li>\n",
    "        <li>Major (likely > \\$1 million and < \\$1 billion)</li>\n",
    "        <li>Minor (likely < \\$1 million)</li>\n",
    "        <li>Unknown</li>\n",
    "    </ol>\n",
    "\n",
    "### Data Cleaning\n",
    "We will clean the data set so only the above attributes are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JakeCarlson/anaconda/envs/MLEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (6,63,79,94,96,114,115) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent maintained:  36.354092102123595 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iyear</th>\n",
       "      <th>extended</th>\n",
       "      <th>country_txt</th>\n",
       "      <th>city</th>\n",
       "      <th>vicinity</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crit1</th>\n",
       "      <th>crit2</th>\n",
       "      <th>crit3</th>\n",
       "      <th>...</th>\n",
       "      <th>nwoundte</th>\n",
       "      <th>propextent</th>\n",
       "      <th>ishostkid</th>\n",
       "      <th>nhostkid</th>\n",
       "      <th>nreleased</th>\n",
       "      <th>dayn</th>\n",
       "      <th>attacktype1_txt_int</th>\n",
       "      <th>targtype1_txt_int</th>\n",
       "      <th>country_txt_int</th>\n",
       "      <th>city_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>False</td>\n",
       "      <td>0.758239</td>\n",
       "      <td>0.161304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.095499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>False</td>\n",
       "      <td>0.758239</td>\n",
       "      <td>0.161304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>False</td>\n",
       "      <td>0.740602</td>\n",
       "      <td>0.150956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>Shanksville</td>\n",
       "      <td>True</td>\n",
       "      <td>0.751555</td>\n",
       "      <td>0.144956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.042810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>False</td>\n",
       "      <td>0.733236</td>\n",
       "      <td>0.452702</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>2281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    iyear  extended    country_txt           city  vicinity  latitude  \\\n",
       "3     0.0     False  United States  New York City     False  0.758239   \n",
       "4     0.0     False  United States  New York City     False  0.758239   \n",
       "5     0.0     False  United States      Arlington     False  0.740602   \n",
       "6     0.0     False  United States    Shanksville      True  0.751555   \n",
       "10    0.0     False          Italy        Palermo     False  0.733236   \n",
       "\n",
       "    longitude  crit1  crit2  crit3    ...     nwoundte  propextent ishostkid  \\\n",
       "3    0.161304   True   True   True    ...          0.0         0.0      True   \n",
       "4    0.161304   True   True   True    ...          0.0         0.0      True   \n",
       "5    0.150956   True   True   True    ...          0.0         0.0      True   \n",
       "6    0.144956   True   True   True    ...          0.0         0.0      True   \n",
       "10   0.452702   True   True   True    ...          0.0         2.0     False   \n",
       "\n",
       "    nhostkid  nreleased      dayn  attacktype1_txt_int  targtype1_txt_int  \\\n",
       "3   0.095499   0.000000  0.000000                    4                 13   \n",
       "4   0.063666   0.000000  0.000000                    4                 13   \n",
       "5   0.063666   0.000000  0.000000                    4                  6   \n",
       "6   0.042810   0.000000  0.000000                    4                 13   \n",
       "10  0.003293   0.001256  0.017857                    0                 12   \n",
       "\n",
       "    country_txt_int  city_int  \n",
       "3                99      2171  \n",
       "4                99      2171  \n",
       "5                99       183  \n",
       "6                99      2724  \n",
       "10               46      2281  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/After_911.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# drop rows without property damage or unknown city\n",
    "orig_len = df.shape[0]\n",
    "df = df[df['property'] == 1]\n",
    "df = df[df['city'] != \"Unknown\"]\n",
    "new_len = df.shape[0]\n",
    "print(\"Percent maintained: \", new_len/orig_len*100, \"%\")\n",
    "\n",
    "# select columns of interest\n",
    "df = df[['iyear', 'imonth', 'iday', 'extended', 'country_txt', 'city', 'vicinity',\n",
    "         'latitude', 'longitude', 'crit1', 'crit2', 'crit3', 'success', 'suicide',\n",
    "         'attacktype1_txt', 'targtype1_txt', 'individual', 'nperps', 'nperpcap', \n",
    "         'claimed', 'claimmode', 'nkill', 'nkillter', 'nwound', \n",
    "         'nwoundte', 'propextent', 'ishostkid', 'nhostkid', 'nreleased']]\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "logical_cols = ['extended', 'vicinity', 'crit1', 'crit2', 'crit3',\n",
    "                'success', 'suicide', 'individual', 'claimed', 'ishostkid']\n",
    "categorical_cols_txt = ['attacktype1_txt', 'targtype1_txt', 'country_txt', 'city']\n",
    "categorical_cols_int = ['claimmode']\n",
    "ratio_cols = ['latitude', 'longitude', 'nperps', 'nperpcap', 'nkill',\n",
    "              'nkillter', 'nwound', 'nwoundte', 'nhostkid', 'nreleased']\n",
    "\n",
    "# replace unknowns with nan\n",
    "logical_replace = dict((l, {-9:np.nan}) for l in ['claimed'])\n",
    "ratio_replace = dict((r, {-99:np.nan, -9:np.nan}) for r in ratio_cols)\n",
    "df.replace(to_replace=logical_replace, inplace=True)\n",
    "df.replace(to_replace=ratio_replace, inplace=True)\n",
    "\n",
    "# replace NA city with mode city for country\n",
    "df['city'] = df.groupby('country_txt')['city'].transform(lambda x: x.fillna(x.mode().iloc[0]))\n",
    "df['latitude'] = df.groupby('country_txt')['latitude'].transform(lambda x: x.fillna(x.mode().iloc[0]))\n",
    "df['longitude'] = df.groupby('country_txt')['longitude'].transform(lambda x: x.fillna(x.mode().iloc[0]))\n",
    "# for c in df.country.values:\n",
    "#     df[df.country == c].fillna()\n",
    "\n",
    "# replace NA's with median for col\n",
    "df.fillna(value=df.median(), inplace=True)\n",
    "\n",
    "# convert logical cols to bools\n",
    "for l in logical_cols:\n",
    "    df[l] = df[l].astype('bool')\n",
    "\n",
    "# normalize ratio cols\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "df[ratio_cols] = min_max_scaler.fit_transform(df[ratio_cols])\n",
    "\n",
    "# standardize date attributes\n",
    "# use year, month, and day to get day number in year\n",
    "day_list = []\n",
    "for r in df[['iyear', 'imonth', 'iday']].iterrows():\n",
    "    # fudge day 0 to 1\n",
    "    if r[1].iday == 0:\n",
    "        day_list.append(\n",
    "            datetime(r[1].iyear, r[1].imonth, 1).timetuple().tm_yday)\n",
    "    else:\n",
    "        day_list.append(\n",
    "            datetime(r[1].iyear, r[1].imonth, r[1].iday).timetuple().tm_yday)\n",
    "        \n",
    "df = df.assign(dayn=day_list)\n",
    "\n",
    "# drop month and day attributes\n",
    "df.drop(['imonth', 'iday'], axis=1, inplace=True)\n",
    "\n",
    "# normalize day number and year col\n",
    "df['iyear'] = df['iyear'].astype(np.float64)\n",
    "df['dayn'] = df['dayn'].astype(np.float64)\n",
    "df[['iyear', 'dayn']] = min_max_scaler.fit_transform(df[['iyear', 'dayn']])\n",
    "\n",
    "# convert categorical cols as ints\n",
    "for c in categorical_cols_int:\n",
    "    df[c] = df[c].astype(np.int64)\n",
    "\n",
    "encoders = {}\n",
    "# one-hot encode categorical cols\n",
    "for c in categorical_cols_txt:\n",
    "    encoders[c] = preprocessing.LabelEncoder()\n",
    "    df[c+'_int'] = encoders[c].fit_transform(df[c])\n",
    "    categorical_cols_int.append(c+'_int')\n",
    "\n",
    "# zero-index propextent\n",
    "df.propextent = df.propextent - 1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7618 entries, 3 to 20953\n",
      "Data columns (total 32 columns):\n",
      "iyear                  7618 non-null float64\n",
      "extended               7618 non-null bool\n",
      "country_txt            7618 non-null object\n",
      "city                   7618 non-null object\n",
      "vicinity               7618 non-null bool\n",
      "latitude               7618 non-null float64\n",
      "longitude              7618 non-null float64\n",
      "crit1                  7618 non-null bool\n",
      "crit2                  7618 non-null bool\n",
      "crit3                  7618 non-null bool\n",
      "success                7618 non-null bool\n",
      "suicide                7618 non-null bool\n",
      "attacktype1_txt        7618 non-null object\n",
      "targtype1_txt          7618 non-null object\n",
      "individual             7618 non-null bool\n",
      "nperps                 7618 non-null float64\n",
      "nperpcap               7618 non-null float64\n",
      "claimed                7618 non-null bool\n",
      "claimmode              7618 non-null int64\n",
      "nkill                  7618 non-null float64\n",
      "nkillter               7618 non-null float64\n",
      "nwound                 7618 non-null float64\n",
      "nwoundte               7618 non-null float64\n",
      "propextent             7618 non-null float64\n",
      "ishostkid              7618 non-null bool\n",
      "nhostkid               7618 non-null float64\n",
      "nreleased              7618 non-null float64\n",
      "dayn                   7618 non-null float64\n",
      "attacktype1_txt_int    7618 non-null int64\n",
      "targtype1_txt_int      7618 non-null int64\n",
      "country_txt_int        7618 non-null int64\n",
      "city_int               7618 non-null int64\n",
      "dtypes: bool(10), float64(13), int64(5), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save full clean data set\n",
    "df.to_csv('./clean-data/After_911_clean.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have done a number of things to prepare our data for modeling. First, we replaced unknown values in each column with the median for that column. Second, we converted attributes that encode a logical value to a boolean. Third, we normalized the ratio attributes so they are all in the range 0 to 1. Fourth, we convert the year, month, and day attribute to a single numeric attribute which represents the day number in the year that the attack occured on. Then we drop the month and day columns. We still want the year attribute because of the change in attack frequency we noticed in Lab 1, so we standardize the year and day number columns. Finally, we one-hot encode all of the categorical attributes in our data set, creating a variety of additional columns that are needed to represent our data in this way.\n",
    "\n",
    "### Crossed Columns\n",
    "We will create several crossed columns to make the data set wider. This will help our model with memorization of the training data. We will cross attack type with property extent, target type, city, and country. We will also cross property extent with target type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iyear</th>\n",
       "      <th>extended</th>\n",
       "      <th>country_txt</th>\n",
       "      <th>city</th>\n",
       "      <th>vicinity</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crit1</th>\n",
       "      <th>crit2</th>\n",
       "      <th>crit3</th>\n",
       "      <th>...</th>\n",
       "      <th>nwoundte</th>\n",
       "      <th>propextent</th>\n",
       "      <th>ishostkid</th>\n",
       "      <th>nhostkid</th>\n",
       "      <th>nreleased</th>\n",
       "      <th>dayn</th>\n",
       "      <th>attacktype1_txt_int</th>\n",
       "      <th>targtype1_txt_int</th>\n",
       "      <th>country_txt_int</th>\n",
       "      <th>city_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>False</td>\n",
       "      <td>0.758239</td>\n",
       "      <td>0.161304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.095499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>False</td>\n",
       "      <td>0.758239</td>\n",
       "      <td>0.161304</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>False</td>\n",
       "      <td>0.740602</td>\n",
       "      <td>0.150956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>Shanksville</td>\n",
       "      <td>True</td>\n",
       "      <td>0.751555</td>\n",
       "      <td>0.144956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.042810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>2724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Palermo</td>\n",
       "      <td>False</td>\n",
       "      <td>0.733236</td>\n",
       "      <td>0.452702</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>2281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    iyear  extended    country_txt           city  vicinity  latitude  \\\n",
       "3     0.0     False  United States  New York City     False  0.758239   \n",
       "4     0.0     False  United States  New York City     False  0.758239   \n",
       "5     0.0     False  United States      Arlington     False  0.740602   \n",
       "6     0.0     False  United States    Shanksville      True  0.751555   \n",
       "10    0.0     False          Italy        Palermo     False  0.733236   \n",
       "\n",
       "    longitude  crit1  crit2  crit3    ...     nwoundte  propextent ishostkid  \\\n",
       "3    0.161304   True   True   True    ...          0.0         0.0      True   \n",
       "4    0.161304   True   True   True    ...          0.0         0.0      True   \n",
       "5    0.150956   True   True   True    ...          0.0         0.0      True   \n",
       "6    0.144956   True   True   True    ...          0.0         0.0      True   \n",
       "10   0.452702   True   True   True    ...          0.0         2.0     False   \n",
       "\n",
       "    nhostkid  nreleased      dayn  attacktype1_txt_int  targtype1_txt_int  \\\n",
       "3   0.095499   0.000000  0.000000                    4                 13   \n",
       "4   0.063666   0.000000  0.000000                    4                 13   \n",
       "5   0.063666   0.000000  0.000000                    4                  6   \n",
       "6   0.042810   0.000000  0.000000                    4                 13   \n",
       "10  0.003293   0.001256  0.017857                    0                 12   \n",
       "\n",
       "    country_txt_int  city_int  \n",
       "3                99      2171  \n",
       "4                99      2171  \n",
       "5                99       183  \n",
       "6                99      2724  \n",
       "10               46      2281  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./clean-data/After_911_clean.csv', index_col=0)\n",
    "\n",
    "logical_cols = ['extended', 'vicinity', 'crit1', 'crit2', 'crit3',\n",
    "                'success', 'suicide', 'individual', 'claimed', 'ishostkid']\n",
    "categorical_cols_txt = ['attacktype1_txt', 'targtype1_txt', 'country_txt', 'city']\n",
    "categorical_cols_int = ['claimmode'] + [x+'_int' for x in categorical_cols_txt]\n",
    "ratio_cols = ['latitude', 'longitude', 'nperps', 'nperpcap', 'nkill',\n",
    "              'nkillter', 'nwound', 'nwoundte', 'nhostkid', 'nreleased']\n",
    "feature_cols = logical_cols + categorical_cols_int + ratio_cols\n",
    "\n",
    "y = df['propextent']\n",
    "X = df.drop(['propextent'], axis=1)\n",
    "y_ints = y.values\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7618 entries, 3 to 20953\n",
      "Data columns (total 32 columns):\n",
      "iyear                  7618 non-null float64\n",
      "extended               7618 non-null bool\n",
      "country_txt            7618 non-null object\n",
      "city                   7618 non-null object\n",
      "vicinity               7618 non-null bool\n",
      "latitude               7618 non-null float64\n",
      "longitude              7618 non-null float64\n",
      "crit1                  7618 non-null bool\n",
      "crit2                  7618 non-null bool\n",
      "crit3                  7618 non-null bool\n",
      "success                7618 non-null bool\n",
      "suicide                7618 non-null bool\n",
      "attacktype1_txt        7618 non-null object\n",
      "targtype1_txt          7618 non-null object\n",
      "individual             7618 non-null bool\n",
      "nperps                 7618 non-null float64\n",
      "nperpcap               7618 non-null float64\n",
      "claimed                7618 non-null bool\n",
      "claimmode              7618 non-null int64\n",
      "nkill                  7618 non-null float64\n",
      "nkillter               7618 non-null float64\n",
      "nwound                 7618 non-null float64\n",
      "nwoundte               7618 non-null float64\n",
      "propextent             7618 non-null float64\n",
      "ishostkid              7618 non-null bool\n",
      "nhostkid               7618 non-null float64\n",
      "nreleased              7618 non-null float64\n",
      "dayn                   7618 non-null float64\n",
      "attacktype1_txt_int    7618 non-null int64\n",
      "targtype1_txt_int      7618 non-null int64\n",
      "country_txt_int        7618 non-null int64\n",
      "city_int               7618 non-null int64\n",
      "dtypes: bool(10), float64(13), int64(5), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "col_names = X.columns.values\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=0.1, random_state=64)\n",
    "for train_idx, test_idx in sss.split(X.values, y.values):\n",
    "    # X_train - 80% training attribute set\n",
    "    # X_test - 20% test attribute set\n",
    "    # y_train - 80% training labels\n",
    "    # y_test - 20% training labels\n",
    "    X_train, X_test = pd.DataFrame(X.values[train_idx], columns=col_names), pd.DataFrame(X.values[test_idx], columns=col_names)\n",
    "#     X_cat_train, X_cat_test = pd.DataFrame(X[categorical_cols_int].values[train_idx], columns=categorical_cols), pd.DataFrame(df_categories.values[test_idx], columns=categorical_cols)\n",
    "    y_train, y_test = pd.DataFrame(y.values[train_idx], columns=[\"propextent\"]), pd.DataFrame(y.values[test_idx], columns=[\"propextent\"])\n",
    "\n",
    "# X_train, X_test = X_train.values, X_test.values\n",
    "y_train, y_test = y_train.values.flatten(), y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JakeCarlson/anaconda/envs/MLEnv/lib/python3.6/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_130 (Dense)            (None, 120)               3120      \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 40)                4840      \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 4)                 164       \n",
      "=================================================================\n",
      "Total params: 8,124\n",
      "Trainable params: 8,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.770711916556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(120, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(40, activation='relu'))\n",
    "    model.add(Dense(output_dim=4, activation='softmax'))\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_dim = X_train[feature_cols].values.shape[1]\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, epochs=10, batch_size=32, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=64)\n",
    "results = cross_val_score(model, X_train[feature_cols].values, y_train, cv=kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attacktype1_txt', 'targtype1_txt']\n",
      "['attacktype1_txt', 'city']\n",
      "['attacktype1_txt', 'country_txt']\n",
      "['attacktype1_txt', 'targtype1_txt']\n",
      "['attacktype1_txt', 'city']\n",
      "['attacktype1_txt', 'country_txt']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_209 to have shape (None, 4) but got array with shape (6856, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-a7f831ef4704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_branched_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m model.fit(X_train_final,\n\u001b[0;32m---> 85\u001b[0;31m           y_train, epochs=10, batch_size=32, verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/MLEnv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1522\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/MLEnv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1379\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1382\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1383\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda/envs/MLEnv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_209 to have shape (None, 4) but got array with shape (6856, 1)"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cross_columns = [['attacktype1_txt','targtype1_txt'],\n",
    "                 ['attacktype1_txt','city'],\n",
    "                 ['attacktype1_txt','country_txt']]\n",
    "\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_branch_outputs = []\n",
    "\n",
    "for cols in cross_columns:\n",
    "    # encode crossed columns as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "\n",
    "    # create crossed labels\n",
    "    print(cols)\n",
    "    X_crossed_train = X_train[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    X_crossed_test = X_test[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "    enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "    X_crossed_train = enc.transform(X_crossed_train)\n",
    "    X_crossed_test = enc.transform(X_crossed_test)\n",
    "    X_ints_train.append( X_crossed_train )\n",
    "    X_ints_test.append( X_crossed_test )\n",
    "\n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32',name = '_'.join(cols))\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "\n",
    "wide_branch = concatenate(all_branch_outputs)\n",
    "\n",
    "all_branch_outputs = []\n",
    "# add in the embeddings\n",
    "for col in categorical_cols_int:\n",
    "    # encode as ints for the embedding\n",
    "    X_ints_train.append( X_train[col].values )\n",
    "    X_ints_test.append( X_test[col].values )\n",
    "\n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "\n",
    "# also get a dense branch of the ratio features\n",
    "all_inputs.append(Input(shape=(X_train[feature_cols].values.shape[1],),sparse=False))\n",
    "x = Dense(units=20, activation='relu')(all_inputs[-1])\n",
    "all_branch_outputs.append( x )\n",
    "\n",
    "# merge the branches together\n",
    "deep_branch = concatenate(all_branch_outputs)\n",
    "deep_branch = Dense(units=50,activation='relu')(deep_branch)\n",
    "deep_branch = Dense(units=10,activation='relu')(deep_branch)\n",
    "\n",
    "final_branch = concatenate([wide_branch, deep_branch])\n",
    "final_branch = Dense(units=4,activation='softmax')(final_branch)\n",
    "\n",
    "model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# model = KerasClassifier(build_fn=build_branched_model, epochs=10, batch_size=32, verbose=0)\n",
    "# kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=64)\n",
    "# results = cross_val_score(model, X_ints_train+X_train[feature_cols].values, y_train, cv=kfold)\n",
    "\n",
    "X_train_final = X_ints_train\n",
    "X_train_final.append(X_train[feature_cols].values)\n",
    "model = build_branched_model()\n",
    "model.fit(X_train_final,\n",
    "          y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLEnv]",
   "language": "python",
   "name": "conda-env-MLEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
