{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - Evaluation and Multi-Layer Perceptron\n",
    "\n",
    "### Eric Smith and Jake Carlson\n",
    "\n",
    "## Introduction\n",
    "In this lab, we will develop a multi-layer perceptron to perform classification on the CIFAR-10 data set. Similar to Lab 3, we will subset the data set to images of trucks and automobiles.\n",
    "\n",
    "The original data set has 60,000 images. 50,000 of these are training images and 10,000 are test images. The images are 32x32 pixels and contain objects from 10 classes. The classes are listed below.\n",
    "- airplane\n",
    "- automobile\n",
    "- bird\n",
    "- cat\n",
    "- deer\n",
    "- dog\n",
    "- frog\n",
    "- horse\n",
    "- ship\n",
    "- truck\n",
    "\n",
    "This data set was collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton for their paper <i>Learning Multiple Layers of Features from Tiny Images</i>. In this study, the authors use several filters to train their model to learn interesting regularities in the set of images, rather than focus on correlations between nearby pixels [1].\n",
    "\n",
    "For this lab, we will use the automobile and truck images. The trucks, in this case, are semi-trucks. We have been garunteed by the people who generated the data set that the classes 'truck' and 'automobile' are mutually exclusive. The automobile class will have images of sedans and SUVs. The truck class will have big trucks only. Neither class has images of pickup trucks.\n",
    "\n",
    "## Business Understanding\n",
    "\n",
    "### Motivations\n",
    "The law treats cars and trucks differently on the road. Trucks often have to stop at weigh stations so their contents can be verified. It would be useful to have a tool that can distinguish between cars and trucks. Once a truck has been identified, a record of the truck and its location can be made so that Customs or local authorities can make sure the truck is checked at the next weigh station.\n",
    "\n",
    "The classification system developed could be deployed in conjunction with CCTV cameras on the highway. This would give authorities real time metrics on how many trucks are passing through an area. If a truck passes by two cameras, our model could incorporate the location of each camera and the time between sightings. This would reduce the necessity of having police officers on the road to monitor the speed of semi-trucks.\n",
    "\n",
    "If a truck is identified as speeding, a police officer could be dispatched to monitor the vehicle. Using a distributed network of cameras on the highway would mean officers could spend more time patrolling residential and commerical areas. The average annual income for a Texas state trooper is \\$60,612 [2]. Positioning a trooper on the highway costs roughly \\$31 an hour. Meanwhile, the cost of running a CCTV camera 24/7 is approximately 54 cents per month [3].\n",
    "\n",
    "Finally, if a trooper is positioned on the highway, people alter their behaviors because they recognize that they are being monitored. If a criminal organization is transporting illicit substances, they can have a lead car drive ahead of the transport truck so officers can be located before the truck passes through an area. However, people often don't recognize when they are being monitored by CCTV camera.\n",
    "\n",
    "### Objectives\n",
    "Our main objective is to accurately pick out a semi-truck from a sea of automobiles. A state trooper can accurately distinguish between a semi-truck and an automobile 100% of the time. But troopers rotate in and out of an area, leaving gaps in the amount of time a road is being monitored. Take the following simplified case: one trooper is assigned to watch a highway for one business day where they start at 8am, end at 5pm, and take an hour for lunch. A second trooper rotates in to monitor the highway starting at 6pm and ending at 3am. The percentage of time the road is covered is given by\n",
    "<br><br>\n",
    "$$t_{officer} = \\frac{24 - ((6-5) + 1 + (6-3))}{24}\\times100 = 79.2\\%$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "79% is our threshold to beat. If our system is monitoring a road 24/7, we want to accurately identify a semi-truck at least 80% of the time to be a viable replacement for a police officer stationed on the highway. If we can achieve this level of accurate identification, we can reduce the cost to monitor a highway per month by\n",
    "<br><br>\n",
    "$$savings = \\frac{60,612/12}{0.54}\\times100 = 935,370\\%$$\n",
    "\n",
    "This objective alone, however, does not say much about the <i>performance</i> of our model. In order for our algorithm to be useful to authorities, it must also be able to quickly identitify potential trucks. Otherwise, the truck could be much further away from the location where the picture was taken. Therefore, the time it takes for our algorithm to identitfy \n",
    "\n",
    "### Evaluation\n",
    "\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "### Data Cleaning\n",
    "We will clean the data set from Lab 3 by reducing the dimensionality using PCA, which showed the least information loss in the transformation across all images in the data set. We will then normalize all of the pixel intensity values so that they are in the range 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Alex Krizhevsky, 2009: <a href=\"http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf\">Learning Multiple Layers of Features from Tiny Images</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MachineLearning]",
   "language": "python",
   "name": "conda-env-MachineLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
